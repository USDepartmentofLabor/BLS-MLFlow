{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d13909",
   "metadata": {},
   "source": [
    "# BLS MLflow Example Notebook 4 Extended- Hugging Face Transformers & Ray Tune Hyperparameter Optimization \n",
    "\n",
    "*Remy Stewart, BLS Civic Digitial Fellow Summer 2022*\n",
    "\n",
    "*The following code builds from a previous script developed by BLS Data Scientist David Oh.*\n",
    "\n",
    "\n",
    "# 1.0 Introduction\n",
    "\n",
    "This notebook extends the base Hugging Face and ONET MLFlow intergration notebook featured within this repository by incorperating the Ray Tune hyperparameter optimization library to support state-of-the-art optimization techniques as logged within the remote BLS MLflow server. This notebook is similar in its code to the base transformers notebook. It therefore focuses on the Ray Tune configuration and does not repeat explanations featured within the original example walkthrough. \n",
    "\n",
    "Hyperparameter optimization is an essential step within the machine learning model development lifecycle to engineer high-performing ML models that are configured with the identified best-suited hyperparameters within both model development and as applied for production use. Hyperparameters can significantly influence model behavior, and deep learning models such as Hugging Face transformers are dependent on a large number of key hyperparameters that are strong candidates for potential tuning.\n",
    "\n",
    "Finding the optimal hyperparameters for a model takes up sizable time within model experimentation, and iterating through a search space of the many potential combinations of multiple hyperparameters can be computationally costly and time inefficient. The Ray Tune library offers a suite of more advanced hyperparameter tuning methods over traditional techniques such as Grid & Random Search that aim to minimize resource demands and direct hyperparameter searches through performance-informed algorithms. Ray Tune also supports MLflow incorperation, which is an essential advantage of the library to ensure our hyperparameter exploration is logged and reproducible via the BLS MLflow server. \n",
    "\n",
    "This notebook features hyperparameter tuning of our original DistilRoBERTa transformers classifier on public ONET data via the Tree-Structured Parzen Estimator (TPE) algorithm grounded on a Bayesian optimization approach. This walkthrough explores both the code incorperation of the TPE optimizer as well as overviews the key features of this technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf4d90b",
   "metadata": {},
   "source": [
    "# 2.0 Set-Up\n",
    "\n",
    "To get started, we'll install Ray Tune if it's not already present in your current environment (which it will be if running this script within the bls-mlflow conda environment) and import our supporting libraries. You'll note at the very end of the library import block the inclusion of `ray.shutdown`, which will successfully end any previous Ray Tune trial initializations as needed in cases such as restarted kernels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b27090fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"ray[tune]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16df1ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Deep learning modules \n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from transformers import ( AutoTokenizer, AutoConfig,\n",
    "                          AutoModelForSequenceClassification, \n",
    "                          TrainingArguments, Trainer, EvalPrediction )\n",
    "import torch\n",
    "\n",
    "# Sklearn modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "# Helper functions\n",
    "import pyfiles\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "from ray.tune.integration.mlflow import MLflowLoggerCallback\n",
    "\n",
    "import mlflow \n",
    "from mlflow.tracking import MlflowClient\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995647d8",
   "metadata": {},
   "source": [
    "We can set an environmental variable to automatically log produced model artifacts within our remote BLS server as linked via its hosted URL. We'll additionally house our hyperparameter tuning runs under the same experiment we created within the original transformers MLflow incorperation example notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c73b6c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_MLFLOW_LOG_ARTIFACTS=1\n"
     ]
    }
   ],
   "source": [
    "%env HF_MLFLOW_LOG_ARTIFACTS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a960d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://<Remote IP>:<Port>\")\n",
    "mlflow.set_experiment('hf-onet-experiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe69158",
   "metadata": {},
   "source": [
    "Using hyperparameter optimization techniques via Ray Tune requires establishing a local file path for the library to record trial performance in order to make prior-informed hyperparameter updates within later tuning trails. I therefore set a local path within the BLS deep learning server I am developing this script within to ensure that Ray Tune will consistently know where to record and reference past optimization trials.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2c79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env TUNE_RESULT_DIR=\"<Ray Trial Directory>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb458b18",
   "metadata": {},
   "source": [
    "# 3.0 Preprocessing & Transformers Set-Up\n",
    "\n",
    "We then load in our data and preprocess it using our helper package methods to transform the data sets for training, validation, and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a87cac77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>GWA</th>\n",
       "      <th>Task_backtranslated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Review and analyze legislation, laws, or publi...</td>\n",
       "      <td>4A2a4</td>\n",
       "      <td>Review and analysis of legislation, laws or pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Review and analyze legislation, laws, or publi...</td>\n",
       "      <td>4A4b6</td>\n",
       "      <td>Review and analysis of legislation, laws or pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Direct or coordinate an organization's financi...</td>\n",
       "      <td>4A4b4</td>\n",
       "      <td>management or coordination of the financial or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Confer with board members, organization offici...</td>\n",
       "      <td>4A4a2</td>\n",
       "      <td>Talk to members of the board, organizational o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Analyze operations to evaluate performance of ...</td>\n",
       "      <td>4A2a4</td>\n",
       "      <td>Analyze the operations to evaluate the perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23009</th>\n",
       "      <td>Unload cars containing liquids by connecting h...</td>\n",
       "      <td>4A3a2</td>\n",
       "      <td>Download vehicles that contain liquids by conn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23010</th>\n",
       "      <td>Copy and attach load specifications to loaded ...</td>\n",
       "      <td>4A1b1</td>\n",
       "      <td>Copy and attach charging specifications to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23011</th>\n",
       "      <td>Start pumps and adjust valves or cables to reg...</td>\n",
       "      <td>4A3a3</td>\n",
       "      <td>Start pumps and adapt valves or cables to regu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23012</th>\n",
       "      <td>Perform general warehouse activities, such as ...</td>\n",
       "      <td>4A1b3</td>\n",
       "      <td>Carrying out general storage activities such a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23013</th>\n",
       "      <td>Perform general warehouse activities, such as ...</td>\n",
       "      <td>4A4c3</td>\n",
       "      <td>Carrying out general storage activities such a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19990 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Task    GWA  \\\n",
       "0      Review and analyze legislation, laws, or publi...  4A2a4   \n",
       "1      Review and analyze legislation, laws, or publi...  4A4b6   \n",
       "2      Direct or coordinate an organization's financi...  4A4b4   \n",
       "3      Confer with board members, organization offici...  4A4a2   \n",
       "4      Analyze operations to evaluate performance of ...  4A2a4   \n",
       "...                                                  ...    ...   \n",
       "23009  Unload cars containing liquids by connecting h...  4A3a2   \n",
       "23010  Copy and attach load specifications to loaded ...  4A1b1   \n",
       "23011  Start pumps and adjust valves or cables to reg...  4A3a3   \n",
       "23012  Perform general warehouse activities, such as ...  4A1b3   \n",
       "23013  Perform general warehouse activities, such as ...  4A4c3   \n",
       "\n",
       "                                     Task_backtranslated  \n",
       "0      Review and analysis of legislation, laws or pu...  \n",
       "1      Review and analysis of legislation, laws or pu...  \n",
       "2      management or coordination of the financial or...  \n",
       "3      Talk to members of the board, organizational o...  \n",
       "4      Analyze the operations to evaluate the perform...  \n",
       "...                                                  ...  \n",
       "23009  Download vehicles that contain liquids by conn...  \n",
       "23010  Copy and attach charging specifications to the...  \n",
       "23011  Start pumps and adapt valves or cables to regu...  \n",
       "23012  Carrying out general storage activities such a...  \n",
       "23013  Carrying out general storage activities such a...  \n",
       "\n",
       "[19990 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onet_base = pd.read_parquet(\"./data/onet_task_gwa.pqt\")\n",
    "onet_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "940bbc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size: 26822\n",
      "Testing Size: 3356\n",
      "Prediction Size: 343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3.1/envs/tf2.34/lib/python3.8/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "training, validation, testing, labels = pyfiles.helpers.data_processing(onet_base)\n",
    "testing = Dataset.from_pandas(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc5506c",
   "metadata": {},
   "source": [
    "There's an important difference to note here between the model instantiation featured in the base transformers example script and how the model needs to be configured for successful use within hyperparameter optimization. We'll need to create a function that can be called to initialize the same DistilRoBERTa model multiple times, as it will be re-launched within hyperparameter tuning across multiple trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b8d69a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "\n",
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained('distilroberta-base', \n",
    "                                                           problem_type='multi_label_classification',\n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693ce5d3",
   "metadata": {},
   "source": [
    "From here we initialize our tokenizer, tokenize our data splits, and create our custom metric computation function. These code blocks are exact replicates from the initial transformers example script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ba8ded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
    "    \n",
    "def tokenization(data, max_length=50):\n",
    "    text = data['Task']\n",
    "    \n",
    "    # Setting longest task description as default max length within tokenization\n",
    "    tokenized = tokenizer(text, padding='max_length', truncation=True, max_length=max_length)\n",
    "    \n",
    "    # Structure Dataset to feature tokenized text, attention masks, and multiclass multilabel membership labels\n",
    "    labels_batch = {key: data[key] for key in data.keys() if key in labels}\n",
    "    labels_matrix = np.zeros((len(text), len(labels)))\n",
    "    for index, label in enumerate(labels):\n",
    "        labels_matrix[:, index] = labels_batch[label]\n",
    "    tokenized['labels'] = labels_matrix.tolist()\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d54903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split & tokenize data- testing out the removal of train batch size\n",
    "tokenized_training = training.map(tokenization, batched=True, remove_columns=training.column_names)\n",
    "tokenized_validation = validation.map(tokenization, batched=True, remove_columns=validation.column_names)\n",
    "tokenized_testing = testing.map(tokenization, batched=True, remove_columns=testing.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba32d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_metrics(predictions, labels):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = pyfiles.helpers.force_prediction(pd.DataFrame(probs.numpy())).to_numpy()\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "  \n",
    "def compute_metrics(pred: EvalPrediction):\n",
    "    model_predictions = pred.predictions[0] if isinstance(pred.predictions, tuple) else pred.predictions\n",
    "    result = multi_label_metrics(predictions=model_predictions, labels=pred.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b935a787",
   "metadata": {},
   "source": [
    "# 4.0 Training Arguments & Trainer\n",
    "\n",
    "We can then establish relevant training arguments for our DistilRoBERTa model, particularly those that remain consistent throughout hyperparameter tuning. We set the `report_to='mlflow'` parameter that ensures that the model's parameters and metrics are successfully recorded within the MLflow server as well as set the `mp_parameters` to an empty whitespace value so this argument does not cause subsequent issues within MLflow logging. \n",
    "\n",
    "An important consideration within hyperparameter tuning is that because searching for optimal model hyperparameters requires launching and recording multiple experimental runs of our model, we are incentivized to both increase runtime performance while simultaneously reduce storage requirements associated with writing our large models as Pytorch binary files. \n",
    "\n",
    "We configure our training arguments to support the first goal by setting the `gradient_accumulation_steps` parameter to allow for more dispersed model updates, which subsequently supports higher data batch sizes for faster training without encountering CUDA memory issues. Additionally, the `save_total_limit` parameter set to 1 will only record one model checkpoint during training, which will reduce the rate of storage accumulation across multiple hyperparameter trials that each require the models to be saved for recording and optimization purposes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8647c34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(output_dir='./results',\n",
    "                                  save_strategy='epoch',\n",
    "                                  save_total_limit=1,\n",
    "                                  do_eval=True,\n",
    "                                  evaluation_strategy='epoch',\n",
    "                                  gradient_accumulation_steps=4,\n",
    "                                  metric_for_best_model='f1',\n",
    "                                  report_to='mlflow', \n",
    "                                  mp_parameters=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37b05037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /home/stewart_r/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"4A1a1\",\n",
      "    \"1\": \"4A1a2\",\n",
      "    \"2\": \"4A1b1\",\n",
      "    \"3\": \"4A1b2\",\n",
      "    \"4\": \"4A1b3\",\n",
      "    \"5\": \"4A2a1\",\n",
      "    \"6\": \"4A2a2\",\n",
      "    \"7\": \"4A2a3\",\n",
      "    \"8\": \"4A2a4\",\n",
      "    \"9\": \"4A2b1\",\n",
      "    \"10\": \"4A2b2\",\n",
      "    \"11\": \"4A2b3\",\n",
      "    \"12\": \"4A2b4\",\n",
      "    \"13\": \"4A2b5\",\n",
      "    \"14\": \"4A2b6\",\n",
      "    \"15\": \"4A3a1\",\n",
      "    \"16\": \"4A3a2\",\n",
      "    \"17\": \"4A3a3\",\n",
      "    \"18\": \"4A3a4\",\n",
      "    \"19\": \"4A3b1\",\n",
      "    \"20\": \"4A3b4\",\n",
      "    \"21\": \"4A3b6\",\n",
      "    \"22\": \"4A4a1\",\n",
      "    \"23\": \"4A4a2\",\n",
      "    \"24\": \"4A4a3\",\n",
      "    \"25\": \"4A4a4\",\n",
      "    \"26\": \"4A4a5\",\n",
      "    \"27\": \"4A4a6\",\n",
      "    \"28\": \"4A4a7\",\n",
      "    \"29\": \"4A4a8\",\n",
      "    \"30\": \"4A4b3\",\n",
      "    \"31\": \"4A4b4\",\n",
      "    \"32\": \"4A4b5\",\n",
      "    \"33\": \"4A4b6\",\n",
      "    \"34\": \"4A4c1\",\n",
      "    \"35\": \"4A4c2\",\n",
      "    \"36\": \"4A4c3\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"4A1a1\": 0,\n",
      "    \"4A1a2\": 1,\n",
      "    \"4A1b1\": 2,\n",
      "    \"4A1b2\": 3,\n",
      "    \"4A1b3\": 4,\n",
      "    \"4A2a1\": 5,\n",
      "    \"4A2a2\": 6,\n",
      "    \"4A2a3\": 7,\n",
      "    \"4A2a4\": 8,\n",
      "    \"4A2b1\": 9,\n",
      "    \"4A2b2\": 10,\n",
      "    \"4A2b3\": 11,\n",
      "    \"4A2b4\": 12,\n",
      "    \"4A2b5\": 13,\n",
      "    \"4A2b6\": 14,\n",
      "    \"4A3a1\": 15,\n",
      "    \"4A3a2\": 16,\n",
      "    \"4A3a3\": 17,\n",
      "    \"4A3a4\": 18,\n",
      "    \"4A3b1\": 19,\n",
      "    \"4A3b4\": 20,\n",
      "    \"4A3b6\": 21,\n",
      "    \"4A4a1\": 22,\n",
      "    \"4A4a2\": 23,\n",
      "    \"4A4a3\": 24,\n",
      "    \"4A4a4\": 25,\n",
      "    \"4A4a5\": 26,\n",
      "    \"4A4a6\": 27,\n",
      "    \"4A4a7\": 28,\n",
      "    \"4A4a8\": 29,\n",
      "    \"4A4b3\": 30,\n",
      "    \"4A4b4\": 31,\n",
      "    \"4A4b5\": 32,\n",
      "    \"4A4b6\": 33,\n",
      "    \"4A4c1\": 34,\n",
      "    \"4A4c2\": 35,\n",
      "    \"4A4c3\": 36\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilroberta-base/resolve/main/pytorch_model.bin from cache at /home/stewart_r/.cache/huggingface/transformers/7a0115a4c463f49bc7ab011872fc4a4b81be681a0434075955d29ac3388e225b.a6127d76576e81475313180aceb31a8688f7a649b80e380d26b5d30302dc83c1\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_training,\n",
    "    eval_dataset=tokenized_validation,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fa1ba1",
   "metadata": {},
   "source": [
    "# 5.0 Hyperparameter Search via TPE & Bayesian Optimization\n",
    "\n",
    "With the standard components required for a transformers model workflow now establish, let's now overview the core features of the TPE Bayesian optimization algorithm we'll be employing for hyperparameter optimization. TPE’s Bayesian approach is grounded on the algorithm’s use of its own recorded performance history of evaluated hyperparameters on a metric of choice to create a probabilistic model used to make well-informed suggestions towards the next set of hyperparameters to evaluate. \n",
    "\n",
    "This is sequentially Bayesian since the model is employing information on prior performance towards the goal of producing posterior estimates that maximizes the probability that the algorithm's selected hyperparameters are set to the optimal value for either minimizing or maximizing the chosen performance metric. The consistent updating of the model's underlying probability distribution used to produce subsequent hyperparameters to test therefore leads to higher-performing model trials with each subsequent prior adjustment with additional trials to learn from.\n",
    "\n",
    "These characteristics of TPE allows the algorithm to make informed selections towards better-performing hyperparameter values in contrast to simpler techniques such as Grid and Random Search. This leads to faster convergance towards the best-performing hyperparameter values that reduces experimentation time and resource demands. \n",
    "\n",
    "## 5.1 Ray Tune Configuration Dictionary & MLflow Callback Intergration\n",
    "\n",
    "Ray Tune's implementation of TPE is supported by providing a configuration dictionary that designates both the hyperparameters that will be included within the search space, as well as the range of values for each hyperparameter the model is allowed to select between when exploring potential optimal values across trials. \n",
    "\n",
    "TPE is unique compared to other Bayesian optimization methods in that it supports both discrete and continuous hyperparameters instead of exclusively continuous search spaces. Ray Tune provides syntax to delineate discrete hyperparameters via `tune.choice` and continous values with `tune.uniform` within the hyperparameter configuration dictionary. `tune.choice` will allow the model to select from any of the specified discrete values, while `tune.uniform` will permit any continuous selection within the minimum and maximum ranges. We therefore set the training sample batch size, model learning rate, potential use of a weight decay parameter, and the selected number of training epoches as our searchable hyperparameters within the Ray Tune configuration dictionary.\n",
    "\n",
    "We'll additionally instantiate an `MLflowLoggerCallback` instance to provide the required arguments for Ray Tune to log its hyperparameter searches into the remote BLS MLflow server. This includes passing the same experiment name we established for the transformer model itself earlier in the script, as well as the `save_artifact=True` parameter to ensure that trial runs are successfully recorded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "791864c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_config(trial): \n",
    "    return { \"per_device_train_batch_size\": tune.choice([8, 16, 32, 64]),\n",
    "             \"learning_rate\": tune.uniform(2e-5, 3e-5),\n",
    "             \"weight_decay\": tune.uniform(0.0, 0.1),\n",
    "             \"num_train_epochs\": tune.choice([3, 5, 7, 10])}\n",
    "\n",
    "callbacks=[MLflowLoggerCallback(\n",
    "        tracking_uri=\"http://<Remote IP>:<Port>\",\n",
    "        experiment_name=\"hf-onet-experiment\",\n",
    "        save_artifact=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c9b8d2",
   "metadata": {},
   "source": [
    "## 5.2 Hyperparameter Training Configuration\n",
    "\n",
    "The next code block both establishes the full configuration of our hyperparameter search as well as launches the search when ran. \n",
    "\n",
    "- `trainer.hyperparameter_search` itself is from the transformers library. The first argument of `hp_space` passes our created configuration dictionary. \n",
    "- `n_trials` specifies how many unique trials should be launched within the search run. This parameter is key to the successful use of the sequential Bayesian strengths of TPE. I've set it to 3 for demonstration purposes, but I'd encourage higher values when this method is used with the direct intention of solidifying hyperparameter selections. \n",
    "- `direction='maximize'` establishes that the search will be aiming to increase our chosen primary metric of F1 score, compared to metrics that are designed to be minimized such as cross-entropy loss. \n",
    "- `backend='ray'` tells transformers to follow the Ray Tune implementation format for hyperparameter optimization, which is particularly helpful when alternative libraries such as Optuna are installed within the environment that transformers may attempt to incorrectly reference. \n",
    "- `search_alg` initializes `HyperOptSearch`, which is the class that provides the implementation of the TPE algorithm. You can see that the metric to optimize has been set to F1 score performance on the evalution set, with the `mode='max'`parameter ensuring that Ray Tune also understands that the TPE algorithm will aim to maximize the F1 score along with the transformer library's aligned passed argument. \n",
    "- `callbacks` establishes the MLflow Callback parameters for the optimization trials, while `local_dir` passes the trial storage directory for each launched trial. \n",
    "- The `resources_per_trial` dictionary flags for Ray Tune that one CPU and one GPU core will be avaliable for the trials, while `verbose` reduces the output verbosity to a lower level since Ray Tune otherwise produces extensive logs. Even the lower level of verbosity is still quite extensive, so you'll have to do a fair amount of scrolling to get to the end of the following block. \n",
    "\n",
    "Finally, you'll also notice that the hyperparameter search is passed into the `best_run` object. `best_run` will retain the best hyperparameters identified across the 3 initialized trials for later reference within our model workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce610e33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_run = trainer.hyperparameter_search(hp_space=tune_config, n_trials=3, direction='maximize', backend='ray',\n",
    "                                         search_alg=HyperOptSearch(metric='eval_f1', mode='max'), \n",
    "                                         callbacks=callbacks, local_dir='<Ray Results Directory>', resources_per_trial={\"cpu\": 1, \"gpu\": 1}, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87e1ae9",
   "metadata": {},
   "source": [
    "# 6.0 Trial Recording within MLflow\n",
    "\n",
    "With the three trial runs now complete, let's switch over to the remote BLS MLflow server's UI at `http://<Remote IP>:<Port>/` to investigate how these trials are logged within MLflow. The trial runs are automatically assigned the objective ID that Ray Tune creates to keep track of individual trials as run names. You'll note that there are only 4 parameters logged contrasted to the 145 parameters captured when we log a complete transformer model, with the logged parameters being the selected values for the hyperparameters being tested for this given run. \n",
    "\n",
    "While the files of the transformer model components such as the Pytorch model and its training arguments are captured in the results folder, we're not able to save our trials as MLflow models through customizing the `mlflow.pyfunc` model flavor as featured in the base transformers example notebook. We do find that some new artifacts have been recorded such as a JSON file of the selected hyperparameter values for the trial run as well as both JSON and CSV files highlighting the metrics values over training epochs. \n",
    "\n",
    "You can think of the logged optimization trials within MLflow less as full models and instead as experimental runs that provide guidance towards how to best create a fully-configured model through the ideal hyperparameters that were identified. These runs are particularly well-suited for MLflow's Compare feature, which allows you to visually contrast metric performance across the tested hyperparameter values:\n",
    "\n",
    "![tuneviz.png](../imgs/tuneviz.png)\n",
    "\n",
    "Comparing both visually and with the actual metric values between the models clearly identifies which tested run is our top performer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fafbdc",
   "metadata": {},
   "source": [
    "# 7.0 Initializing the Best Tuned Model\n",
    "\n",
    "We can also correborate our identification of which optimization trial and its associated hyperparameters achieved the highest performance on the model metrics within MLflow through accessing our stored `best_run` object as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a05ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run.hyperparameters.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58fe717",
   "metadata": {},
   "source": [
    "With this insight gained towards optimal hyperparameters, we can now move towards logging our tuned transformers model more comprehensively within MLflow. The Ray Tune trials artifact logging included both the Pytorch model file and its associated training arguments that we can use to reinitialize our model with the same hyperparameter values set within the best performing trial. We use the `MLflowClient` to directly download these files into a temporary directory through referencing both the model run ID and the artifact directory path of the best performing trial. We can then use both transformers and Pytorch loading methods to bring in the same model and its training arguments into our workspace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2034721",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "tempdir = tempfile.mkdtemp()\n",
    "model_path = client.download_artifacts(\"<Model Run>\", \"<Logged Model Checkpoint>\", tempdir)\n",
    "\n",
    "loaded_trial = AutoModelForSequenceClassification.from_pretrained(model_path, problem_type='multi_label_classification',\n",
    "                                                                    num_labels=len(labels), id2label=id2label,\n",
    "                                                                    label2id=label2id)\n",
    "loaded_arguments = torch.load(os.path.join(model_path, 'training_args.bin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51e232f",
   "metadata": {},
   "source": [
    "To combine the parameters, metrics, and artifacts from training, validation, to testing, the model will need to be re-ran separate from the hyperparameter tuning for it to be constructed properly as a full model when logging into MLflow. We therefore reinitialize the Trainer with the loaded model and training arguments and record the performance on the training and evaluation data into MLflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de4617ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=loaded_trial,\n",
    "    args=loaded_arguments,\n",
    "    train_dataset=tokenized_training,\n",
    "    eval_dataset=tokenized_validation,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eefba515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 26822\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 4190\n",
      "Trainer is attempting to log a value of \"{0: '4A1a1', 1: '4A1a2', 2: '4A1b1', 3: '4A1b2', 4: '4A1b3', 5: '4A2a1', 6: '4A2a2', 7: '4A2a3', 8: '4A2a4', 9: '4A2b1', 10: '4A2b2', 11: '4A2b3', 12: '4A2b4', 13: '4A2b5', 14: '4A2b6', 15: '4A3a1', 16: '4A3a2', 17: '4A3a3', 18: '4A3a4', 19: '4A3b1', 20: '4A3b4', 21: '4A3b6', 22: '4A4a1', 23: '4A4a2', 24: '4A4a3', 25: '4A4a4', 26: '4A4a5', 27: '4A4a6', 28: '4A4a7', 29: '4A4a8', 30: '4A4b3', 31: '4A4b4', 32: '4A4b5', 33: '4A4b6', 34: '4A4c1', 35: '4A4c2', 36: '4A4c3'}\" for key \"id2label\" as a parameter. MLflow's log_param() only accepts values no longer than 250 characters so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'4A1a1': 0, '4A1a2': 1, '4A1b1': 2, '4A1b2': 3, '4A1b3': 4, '4A2a1': 5, '4A2a2': 6, '4A2a3': 7, '4A2a4': 8, '4A2b1': 9, '4A2b2': 10, '4A2b3': 11, '4A2b4': 12, '4A2b5': 13, '4A2b6': 14, '4A3a1': 15, '4A3a2': 16, '4A3a3': 17, '4A3a4': 18, '4A3b1': 19, '4A3b4': 20, '4A3b6': 21, '4A4a1': 22, '4A4a2': 23, '4A4a3': 24, '4A4a4': 25, '4A4a5': 26, '4A4a6': 27, '4A4a7': 28, '4A4a8': 29, '4A4b3': 30, '4A4b4': 31, '4A4b5': 32, '4A4b6': 33, '4A4c1': 34, '4A4c2': 35, '4A4c3': 36}\" for key \"label2id\" as a parameter. MLflow's log_param() only accepts values no longer than 250 characters so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4190' max='4190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4190/4190 15:48, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.060143</td>\n",
       "      <td>0.668600</td>\n",
       "      <td>0.819636</td>\n",
       "      <td>0.576877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.060942</td>\n",
       "      <td>0.675154</td>\n",
       "      <td>0.824253</td>\n",
       "      <td>0.588796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.063044</td>\n",
       "      <td>0.672077</td>\n",
       "      <td>0.823510</td>\n",
       "      <td>0.583135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.064608</td>\n",
       "      <td>0.673414</td>\n",
       "      <td>0.826925</td>\n",
       "      <td>0.583433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.065929</td>\n",
       "      <td>0.675896</td>\n",
       "      <td>0.829078</td>\n",
       "      <td>0.585518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.067080</td>\n",
       "      <td>0.676943</td>\n",
       "      <td>0.829248</td>\n",
       "      <td>0.586710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.067927</td>\n",
       "      <td>0.678137</td>\n",
       "      <td>0.830263</td>\n",
       "      <td>0.588498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.068793</td>\n",
       "      <td>0.679162</td>\n",
       "      <td>0.831030</td>\n",
       "      <td>0.587306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.069479</td>\n",
       "      <td>0.677809</td>\n",
       "      <td>0.832044</td>\n",
       "      <td>0.584625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.069436</td>\n",
       "      <td>0.677673</td>\n",
       "      <td>0.830960</td>\n",
       "      <td>0.587902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3356\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-419\n",
      "Configuration saved in ./results/checkpoint-419/config.json\n",
      "Model weights saved in ./results/checkpoint-419/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-2316] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3356\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-838\n",
      "Configuration saved in ./results/checkpoint-838/config.json\n",
      "Model weights saved in ./results/checkpoint-838/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-2702] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3356\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-1257\n",
      "Configuration saved in ./results/checkpoint-1257/config.json\n",
      "Model weights saved in ./results/checkpoint-1257/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-419] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3356\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-1676\n",
      "Configuration saved in ./results/checkpoint-1676/config.json\n",
      "Model weights saved in ./results/checkpoint-1676/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1257] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3356\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-2095\n",
      "Configuration saved in ./results/checkpoint-2095/config.json\n",
      "Model weights saved in ./results/checkpoint-2095/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-838] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3356\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-2514\n",
      "Configuration saved in ./results/checkpoint-2514/config.json\n",
      "Model weights saved in ./results/checkpoint-2514/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1676] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3356\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-2933\n",
      "Configuration saved in ./results/checkpoint-2933/config.json\n",
      "Model weights saved in ./results/checkpoint-2933/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-2095] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3356\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-3352\n",
      "Configuration saved in ./results/checkpoint-3352/config.json\n",
      "Model weights saved in ./results/checkpoint-3352/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-2514] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3356\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-3771\n",
      "Configuration saved in ./results/checkpoint-3771/config.json\n",
      "Model weights saved in ./results/checkpoint-3771/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-2933] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3356\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-4190\n",
      "Configuration saved in ./results/checkpoint-4190/config.json\n",
      "Model weights saved in ./results/checkpoint-4190/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-3771] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Logging artifacts. This may take time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4190, training_loss=0.01836893774729071, metrics={'train_runtime': 930.1294, 'train_samples_per_second': 288.368, 'train_steps_per_second': 4.505, 'total_flos': 3471854254794600.0, 'train_loss': 0.01836893774729071, 'epoch': 10.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907001fe",
   "metadata": {},
   "source": [
    "Since ideally identifying optimal hyperparameters would make us confident to then move forward to record model performance on our held-out testing data, let's go ahead and generate predictions on a pseudo-test set and log the computed performance metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e392ca06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 343\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "707211ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_metrics = predictions.metrics\n",
    "mlflow.log_metrics(pred_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13088d4e",
   "metadata": {},
   "source": [
    "Let's resave our model following this additional training into the temporary directory we created earlier and then use the `model_loader_hf` script we established within the base transformers notebook to log our model as a custom `mlflow.pyfunc` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cbabe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /tmp/tmpv4uapgd_/./results/run-41b8700e/checkpoint-4190/config.json\n",
      "Model weights saved in /tmp/tmpv4uapgd_/./results/run-41b8700e/checkpoint-4190/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/tmpv4uapgd_/./results/run-41b8700e/checkpoint-4190/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/tmpv4uapgd_/./results/run-41b8700e/checkpoint-4190/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/tmp/tmpv4uapgd_/./results/run-41b8700e/checkpoint-4190/tokenizer_config.json',\n",
       " '/tmp/tmpv4uapgd_/./results/run-41b8700e/checkpoint-4190/special_tokens_map.json',\n",
       " '/tmp/tmpv4uapgd_/./results/run-41b8700e/checkpoint-4190/vocab.json',\n",
       " '/tmp/tmpv4uapgd_/./results/run-41b8700e/checkpoint-4190/merges.txt',\n",
       " '/tmp/tmpv4uapgd_/./results/run-41b8700e/checkpoint-4190/added_tokens.json',\n",
       " '/tmp/tmpv4uapgd_/./results/run-41b8700e/checkpoint-4190/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_trial.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68988c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.pyfunc.log_model(\"best_model\", \n",
    "                            data_path=model_path, \n",
    "                            code_path=[\"./pyfiles/model_loader_hf.py\"], \n",
    "                            loader_module=\"model_loader_hf\",\n",
    "                            conda_env=\"conda.yaml\")\n",
    "\n",
    "mlflow.log_artifact(\"hf_raytune_example_4_extended.ipynb\")\n",
    "mlflow.log_artifact(\"./pyfiles/helpers.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "990c720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dfc822",
   "metadata": {},
   "source": [
    "By ending the model run we've now successfully incorperated hyperparameter tuning via the TPE Bayesian optimization approach from initial parameter exploration all the way to generating predictions on held-out data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b62fa7a496eaa7d4003b27f2d5f7695055336a82372c34d6dbb2c6e9c845aba2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
