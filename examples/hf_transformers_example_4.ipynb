{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1087d8e6",
   "metadata": {},
   "source": [
    "# BLS MLflow Example Notebook 4- Hugging Face Transformers & ONET\n",
    "*Remy Stewart, BLS Civic Digitial Fellow Summer 2022*\n",
    "\n",
    "*The following code builds from a previous script developed by BLS Data Scientist David Oh*.\n",
    "\n",
    "\n",
    "# 1.0 Introduction\n",
    "\n",
    "This notebook provides a walkthrough for how to integrate MLflow into a machine learning pipeline featuring  Hugging Face's transformers library. Transformers are state-of-the-art neural network models for natural language processing that are ideal for language-based ML applications at the BLS. This example notebook delineates how to incorperate Mlflow's features with the transformers library. Please refer to the first example notebook titled \"sklearn_logreg_example_1\" for an introduction to MLflow's core API, as well as to the BLS MLflow User Guide for a comprehensive overview of MLflow overall. \n",
    "\n",
    "There is no current model flavor for Huggingface transformers within Mlflow in contrast from other deep learning libraries such as Pytorch and Tensorflow. While Huggingface includes native intergration for MLOps-based logging through platforms such as Mlflow that you'll see featured within this notebook, there are multiple points of further customization required to comprehensively track the many features of transformers models within the BLS Mlflow server. We'll walk through these in detail for easy replication of the following methods within other transformer-based applications. \n",
    "\n",
    "The data and modeling goal in this example are the same as from the first Scikit-learn notebook. We will be predicting which tasks are associated with 37 potential General Work Activities (GWAs) from public data sourced from the Occupational Information Network's (ONET) occupational requirements content module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff3d70d",
   "metadata": {},
   "source": [
    "# 2.0 Set-Up\n",
    "\n",
    "Let's import our standard ML libraries, libraries for deep learning applications including transformers itself, Hugging Face's associated Dataset module, Pytorch, as well as Scikit-learn methods for splitting our data and computing performance metrics. We additionally retrieve a few customized modules such as a GPU manager for the BLS server this script is trained within along with a set of helper functions for tasks such as dataset splitting and generating multilabel predictions. We also import Mlflow itself along with a few new MLflow modules that we'll explore further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6d0a98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Deep learning modules \n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EvalPrediction\n",
    "import torch\n",
    "\n",
    "# Sklearn modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "# Helper functions\n",
    "import pyfiles\n",
    "\n",
    "# MLflow modules\n",
    "import mlflow\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "from mlflow.types import DataType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568bb1a9",
   "metadata": {},
   "source": [
    "We'll want to start by configuring our virtual environment to support the intergration of our MLflow server with Hugging Face's transformers. We set an environmental variable within our current conda environment to configure our MLflow server's artifact logging directory as the location to store our logged model training checkpoint files in. This ensures that artifacts will be successfully recorded within the MLflow UI following our transformer model's training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee548b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_MLFLOW_LOG_ARTIFACTS=1\n"
     ]
    }
   ],
   "source": [
    "%env HF_MLFLOW_LOG_ARTIFACTS=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e5553b",
   "metadata": {},
   "source": [
    "We then set our tracking URI to establish our connection with the BLS MLflow server and set our run to its designated experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d5fe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://<Remote IP>:<Port>\")\n",
    "mlflow.set_experiment('hf-onet-experiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78ff28d",
   "metadata": {},
   "source": [
    "## 2.1 Importing Data\n",
    "\n",
    "We're now ready to load in our ONET data file, where you'll notice a new column called \"Task_backtranslated\" compared to the previous example notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e229fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>GWA</th>\n",
       "      <th>Task_backtranslated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Review and analyze legislation, laws, or publi...</td>\n",
       "      <td>4A2a4</td>\n",
       "      <td>Review and analysis of legislation, laws or pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Review and analyze legislation, laws, or publi...</td>\n",
       "      <td>4A4b6</td>\n",
       "      <td>Review and analysis of legislation, laws or pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Direct or coordinate an organization's financi...</td>\n",
       "      <td>4A4b4</td>\n",
       "      <td>management or coordination of the financial or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Confer with board members, organization offici...</td>\n",
       "      <td>4A4a2</td>\n",
       "      <td>Talk to members of the board, organizational o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Analyze operations to evaluate performance of ...</td>\n",
       "      <td>4A2a4</td>\n",
       "      <td>Analyze the operations to evaluate the perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23009</th>\n",
       "      <td>Unload cars containing liquids by connecting h...</td>\n",
       "      <td>4A3a2</td>\n",
       "      <td>Download vehicles that contain liquids by conn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23010</th>\n",
       "      <td>Copy and attach load specifications to loaded ...</td>\n",
       "      <td>4A1b1</td>\n",
       "      <td>Copy and attach charging specifications to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23011</th>\n",
       "      <td>Start pumps and adjust valves or cables to reg...</td>\n",
       "      <td>4A3a3</td>\n",
       "      <td>Start pumps and adapt valves or cables to regu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23012</th>\n",
       "      <td>Perform general warehouse activities, such as ...</td>\n",
       "      <td>4A1b3</td>\n",
       "      <td>Carrying out general storage activities such a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23013</th>\n",
       "      <td>Perform general warehouse activities, such as ...</td>\n",
       "      <td>4A4c3</td>\n",
       "      <td>Carrying out general storage activities such a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19990 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Task    GWA  \\\n",
       "0      Review and analyze legislation, laws, or publi...  4A2a4   \n",
       "1      Review and analyze legislation, laws, or publi...  4A4b6   \n",
       "2      Direct or coordinate an organization's financi...  4A4b4   \n",
       "3      Confer with board members, organization offici...  4A4a2   \n",
       "4      Analyze operations to evaluate performance of ...  4A2a4   \n",
       "...                                                  ...    ...   \n",
       "23009  Unload cars containing liquids by connecting h...  4A3a2   \n",
       "23010  Copy and attach load specifications to loaded ...  4A1b1   \n",
       "23011  Start pumps and adjust valves or cables to reg...  4A3a3   \n",
       "23012  Perform general warehouse activities, such as ...  4A1b3   \n",
       "23013  Perform general warehouse activities, such as ...  4A4c3   \n",
       "\n",
       "                                     Task_backtranslated  \n",
       "0      Review and analysis of legislation, laws or pu...  \n",
       "1      Review and analysis of legislation, laws or pu...  \n",
       "2      management or coordination of the financial or...  \n",
       "3      Talk to members of the board, organizational o...  \n",
       "4      Analyze the operations to evaluate the perform...  \n",
       "...                                                  ...  \n",
       "23009  Download vehicles that contain liquids by conn...  \n",
       "23010  Copy and attach charging specifications to the...  \n",
       "23011  Start pumps and adapt valves or cables to regu...  \n",
       "23012  Carrying out general storage activities such a...  \n",
       "23013  Carrying out general storage activities such a...  \n",
       "\n",
       "[19990 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onet_base = pd.read_parquet(\"./data/onet_task_gwa.pqt\")\n",
    "onet_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84142bc",
   "metadata": {},
   "source": [
    "These represent additional records generated from the original task descriptions through a language translation data augmentation strategy. Fine-tuning a pre-trained transformer model towards a specific goal such as robust GWA membership prediction per task is best supported by having as many records to train on as possible. The records were processed by a series of translation models [available through Hugging Face](https://huggingface.co/Helsinki-NLP) from the University of Helsinki's Language Technology Research Group by converting the original English text into Spanish, then German, and then back to English. This data augmentation strategy provides us with more task examples for our model that are the right balance of being conceptually similar to the original tasks but varying enough to provide additional information for our model within training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5c9e45",
   "metadata": {},
   "source": [
    "# 3.0 Model Preparation\n",
    "\n",
    "We'll now go through the core steps for establishing a transformers model pipeline by preparing & tokenizing our data sets, establishing the model, and specifying its performance metrics. This section doesn't include any direct MLflow intergration, but we'll walk through the process either way to ensure our understanding for each component.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed442e2d",
   "metadata": {},
   "source": [
    "## 3.1 Splitting Datasets & Instantiating the Model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9abae48",
   "metadata": {},
   "source": [
    "We'll draw from our helper function file to transform the original data frame into columns for each GWA, split the data sets, and convert the data splits into transformer Datasets. We will use 78% of our data set for training, 20% for testing, and 2% for model prediction following our logging and loading of the model into MLflow. This function keeps the backtranslated examples within the training set to prevent data leakage within the testing & prediction sets given these record's non-independence from the original task text. \n",
    "\n",
    "While this function converts the training and testing set into transformer Datasets, it leaves the prediction sample as an original Pandas Dataframe. This is because we'll want to test our model's ability to successfully convert the data and generate predictions when it's loaded in directly from MLflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aca582c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size: 26822\n",
      "Testing Size: 3356\n",
      "Prediction Size: 343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3.1/envs/tf2.34/lib/python3.8/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "training, testing, prediction, labels = pyfiles.helpers.hf_data_processing(onet_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092dd8ff",
   "metadata": {},
   "source": [
    "Our pre-trained transformers model of choice will be **DistilRoBERTa**, which is available for download directly from Hugging Face's model hub. DistilRoBERTa combines the performance advancements of [RoBERTa](https://arxiv.org/pdf/1907.11692.pdf) building from the base BERT model that established transformers into mainstream deep learning use, with model compression through the [knowledge distallation](https://arxiv.org/pdf/1910.01108.pdf) technique. DistilRoBERTa strikes an ideal balance between high performance towards classification tasks with being a smaller model compared to alternative transformers that requires less computing resources and subsequently promotes faster run times.    \n",
    "\n",
    "We additionally create two dictionaries with the first featuring the 37 original GWA codes to their equivalent numerical encoding used within our model, and the corollary mapping of said numbers back to their original labels. These dictionaries are provided directly to the model as stored attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24555b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('distilroberta-base', \n",
    "                                                           problem_type='multi_label_classification',\n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7291c2ed",
   "metadata": {},
   "source": [
    "## 3.2 Tokenization\n",
    "\n",
    "The following function defines how the DistilRoBERTa text tokenizer should process each of the data sets. It tokenizes the tasks in batches following the unique [tokenization approach](https://huggingface.co/docs/transformers/tokenizer_summary) required for our specific transformer model, processing individual task text into vectors that can be read into the model that additionally includes the multi-label multi-class GWA membership output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd5f0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(data):\n",
    "    text = data['Task']\n",
    "    \n",
    "    # Setting longest task description as default max length within tokenization\n",
    "    tokenized = tokenizer(text, padding='max_length')\n",
    "    \n",
    "    # Structure Dataset to feature tokenized text, attention masks, and multiclass multilabel membership labels\n",
    "    labels_batch = {key: data[key] for key in data.keys() if key in labels}\n",
    "    labels_matrix = np.zeros((len(text), len(labels)))\n",
    "    for index, label in enumerate(labels):\n",
    "        labels_matrix[:, index] = labels_batch[label]\n",
    "        tokenized['labels'] = labels_matrix.tolist()\n",
    "\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc37257d",
   "metadata": {},
   "source": [
    "We then load in DistilRoBERTa's associated tokenizer, process the training and testing set in batches based on GWA column, and replace the original column names with transformer's preferred column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa50ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilroberta-base')\n",
    "\n",
    "tokenized_training = training.map(tokenization, batched=True, remove_columns=training.column_names)\n",
    "tokenized_testing = testing.map(tokenization, batched=True, remove_columns=testing.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435e19c1",
   "metadata": {},
   "source": [
    "## 3.3 Metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb97816",
   "metadata": {},
   "source": [
    "We'll use the F1 score, ROC AUC, and accuracy metrics to measure model performance for our multi-label multi-class task. This code is adapted from a [script developed](https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/) by Data Scientist Jesus Leal Trujillo designed to compute accurate metrics when performing multilabel classification tasks with transformers. It additionally calls our `helpers_hf.force_prediction` function to ensure at least one GWA assignment for each input task similar to our approach featured in the previous Scikit-learn example notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8881e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_metrics(predictions, labels):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = helpers.force_prediction(pd.DataFrame(probs.numpy())).to_numpy()\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "  \n",
    "def compute_metrics(pred: EvalPrediction):\n",
    "    model_predictions = pred.predictions[0] if isinstance(pred.predictions, tuple) else pred.predictions\n",
    "    result = multi_label_metrics(predictions=model_predictions, labels=pred.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa49b75",
   "metadata": {},
   "source": [
    "# 4.0 Model Training \n",
    "\n",
    "We have almost all of the necessary components established to train our model, short some final configuration of our training arguments relevant to MLflow logging. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4ce75b",
   "metadata": {},
   "source": [
    "## 4.1 Training Arguments & Trainer\n",
    "\n",
    "We'll configure a selection of training arguments for our DistilRoBERTa model that prioritizes faster run times and preserving GPU memory for our example workflow, such as with completing only 1 epoch of training and using small batch sizes to prevent memory overload.  \n",
    "\n",
    "There are two parameters that are of particular importance to our goal of MLflow tracking intergration for our model. `report_to='mlflow'` clearly implies that this parameter cues our trainer to report its logged values to our linked MLflow server. `mp_parameters` is much less intuitive in its importance than `report_to`. This argument is set as a empty string as its default value and it doesn't have a description within the `TrainingArguments` [documentation](https://huggingface.co/docs/transformers/v4.20.1/en/main_classes/trainer#transformers.TrainingArguments). My brief research on the argument has lead me to suspect that it may be designed for model parallelization within cloud computing platforms such as Amazon Sagemaker. What's most important for our purposes is to use a white space to replace this empty string, as otherwise it will cause logging errors within MLflow's `log_parameters`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5086db00",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir='./results', \n",
    "                                  num_train_epochs=1,\n",
    "                                  per_device_train_batch_size=8,\n",
    "                                  per_device_eval_batch_size=8,\n",
    "                                  save_strategy='epoch',\n",
    "                                  save_total_limit=3,\n",
    "                                  learning_rate=3e-5,\n",
    "                                  do_eval=True,\n",
    "                                  evaluation_strategy='epoch',\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  metric_for_best_model='f1',\n",
    "                                  report_to=\"mlflow\", \n",
    "                                  mp_parameters=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52892105",
   "metadata": {},
   "source": [
    "We're now ready to initialize our full model trainer with the DistilRoBERTa model itself, its configured training arguments, its training and testing sets, and the custom function to compute performance metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c87192c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_training,\n",
    "    eval_dataset=tokenized_testing,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3704906",
   "metadata": {},
   "source": [
    "## 4.2 Training the Model \n",
    "\n",
    "Running `trainer.train` automatically cues transformers to log all of the set parameters and generated performance metrics during the training of our model to our MLflow server. We won't have to make any calls to methods such as `mlflow.log_parameters` or `mlflow.log_metrics` ourselves thanks to our earlier steps to configure our transformer  model to report to MLflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e75db8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 26822\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3353\n",
      "Trainer is attempting to log a value of \"{0: '4A1a1', 1: '4A1a2', 2: '4A1b1', 3: '4A1b2', 4: '4A1b3', 5: '4A2a1', 6: '4A2a2', 7: '4A2a3', 8: '4A2a4', 9: '4A2b1', 10: '4A2b2', 11: '4A2b3', 12: '4A2b4', 13: '4A2b5', 14: '4A2b6', 15: '4A3a1', 16: '4A3a2', 17: '4A3a3', 18: '4A3a4', 19: '4A3b1', 20: '4A3b4', 21: '4A3b6', 22: '4A4a1', 23: '4A4a2', 24: '4A4a3', 25: '4A4a4', 26: '4A4a5', 27: '4A4a6', 28: '4A4a7', 29: '4A4a8', 30: '4A4b3', 31: '4A4b4', 32: '4A4b5', 33: '4A4b6', 34: '4A4c1', 35: '4A4c2', 36: '4A4c3'}\" for key \"id2label\" as a parameter. MLflow's log_param() only accepts values no longer than 250 characters so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'4A1a1': 0, '4A1a2': 1, '4A1b1': 2, '4A1b2': 3, '4A1b3': 4, '4A2a1': 5, '4A2a2': 6, '4A2a3': 7, '4A2a4': 8, '4A2b1': 9, '4A2b2': 10, '4A2b3': 11, '4A2b4': 12, '4A2b5': 13, '4A2b6': 14, '4A3a1': 15, '4A3a2': 16, '4A3a3': 17, '4A3a4': 18, '4A3b1': 19, '4A3b4': 20, '4A3b6': 21, '4A4a1': 22, '4A4a2': 23, '4A4a3': 24, '4A4a4': 25, '4A4a5': 26, '4A4a6': 27, '4A4a7': 28, '4A4a8': 29, '4A4b3': 30, '4A4b4': 31, '4A4b5': 32, '4A4b6': 33, '4A4c1': 34, '4A4c2': 35, '4A4c3': 36}\" for key \"label2id\" as a parameter. MLflow's log_param() only accepts values no longer than 250 characters so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3353' max='3353' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3353/3353 14:26, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>0.067361</td>\n",
       "      <td>0.605961</td>\n",
       "      <td>0.778505</td>\n",
       "      <td>0.529499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3356\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-3353\n",
      "Configuration saved in ./results/checkpoint-3353/config.json\n",
      "Model weights saved in ./results/checkpoint-3353/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/checkpoint-3353 (score: 0.6059611703582172).\n",
      "Logging artifacts. This may take time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3353, training_loss=0.09345755788983426, metrics={'train_runtime': 837.82, 'train_samples_per_second': 32.014, 'train_steps_per_second': 4.002, 'total_flos': 3555258286958592.0, 'train_loss': 0.09345755788983426, 'epoch': 1.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18330b4c",
   "metadata": {},
   "source": [
    "We can see that we've successfully completed our model training and obtained our performance metrics on the test set. If you were to visit the MLflow UI for this run at this point in this demo, you'd see that a range of parameters, metrics, and artifacts such as saved checkpoints have been successfully logged. However, there are a few key components to our logged model still missing that we'll want to take some additional steps to add into MLflow. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7474fd",
   "metadata": {},
   "source": [
    "# 5.0 Customized Model Logging\n",
    "\n",
    "As mentioned at the start of this demo script, Transformers models are not currently supported as one of MLflow's established model flavors, meaning that there isn't a prexisting method such as `mlflow.sklearn.log_model` to easily log our model into the server and ensure its seamless retrieval in the future. However, all flavors inherit MLflow's model base class `mlflow.pyfunc`, which we'll be able use to successfully save and retrieve models without currently specified flavors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6502a374",
   "metadata": {},
   "source": [
    "## 5.1 Model Loader Class\n",
    "\n",
    "The key step we need to take to use `mlflow.pyfunc.log_model` for our fine-runed DistilRoBERTa model is to customized our own class known as a **model loader**. Creating a model loader script guides MLflow towards knowing how to instantiate a new instance of the model after it's logged into the server. We'll use the loader as a separate Python file within our logging, but since we'd like to review the script itself we'll write the file internally through `%%writefile`\n",
    "\n",
    "Model loaders need to include three primary components- a model initialization method, a method for how to generate predictions on future data, and a method for calling and loading the customized model from a specified path (which for our purposes will be from our MLflow server). The methods to achieve these goals should import their required packages directly so they can be called upon in production environments. You can add additional methods to your customized model loader as well.\n",
    "\n",
    "We'll include these features through a class titled `TransformerONET`. Initializing a `TransformerONET` instance automatically retrieves our fine-tuned DistilRoBERTa model, its model configuration, and its tokenizer. We'll add our `helpers_hf.force_prediction` function into the model loader script so we can access this prediction converter within `TransformersONET` without having to package the model loader script along with the helpers_hf file. \n",
    "- `predict` tokenizes passed input data, generates predictions, and then forces at least one GWA assignment for each input task through `force_prediction`.\n",
    "- Finally, `_load_pyfunc` simply initializes the TransformerONET model from a passed directory path, which for us will be MLflow's Model Registry. The method must be consistently labeled as `_load_pyfunc` within customized model loaders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c4a339d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_loader_hf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"./pyfiles/model_loader_hf.py\"\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers.models.auto import AutoConfig, AutoModelForSequenceClassification\n",
    "from transformers.models.auto.tokenization_auto import AutoTokenizer\n",
    "\n",
    "class TransformerONET:\n",
    "    def __init__(self, model_name: str, tokenizer = None):\n",
    "        self.model_name = model_name\n",
    "        self.config = AutoConfig.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer or model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, config=self.config)\n",
    "    \n",
    "    def force_prediction(self, predicted_probs_df):\n",
    "        import pandas\n",
    "        import numpy as np\n",
    "        \n",
    "        predicted_probs_df[predicted_probs_df > 0.5] = 1\n",
    "        predicted_prob_df_nomax = predicted_probs_df[predicted_probs_df.max(axis=1) < 0.5]\n",
    "        predicted_prob_df_nomax.values[range(len(predicted_prob_df_nomax.index)), \n",
    "                                          np.argmax(predicted_prob_df_nomax.values, axis=1)] = 1\n",
    "        all_predicted = predicted_prob_df_nomax.combine_first(predicted_probs_df)\n",
    "        all_predicted[all_predicted != 1] = 0\n",
    "        return all_predicted\n",
    "        \n",
    "    def predict(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        import torch\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        from datasets import Dataset\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Tokenize the passed data set\n",
    "            data = Dataset.from_pandas(data)\n",
    "            inputs = self.tokenizer(data['Task'], padding=True, return_tensors='pt')\n",
    "        \n",
    "            # Send data set to GPU for predictions by GWA column \n",
    "            if self.model.device.index != None:\n",
    "                torch.cuda.empty_cache()\n",
    "                for key in inputs.keys():\n",
    "                    inputs[key] = inputs[key].to(self.model.device.index)    \n",
    "\n",
    "            # Generate model predictions and retrieve the produced probabilities\n",
    "            predictions = self.model(**inputs)\n",
    "            probs = torch.nn.Softmax(dim=1)(predictions.logits)\n",
    "            probs = probs.detach().cpu().numpy()\n",
    "            \n",
    "            # Force at least one prediction for each task & convert numeric column codes to original GWA code labels\n",
    "            outputs = self.force_prediction(pd.DataFrame(probs[:,]))      \n",
    "            outputs = outputs.rename(self.config.id2label, axis=1)\n",
    "       \n",
    "        return outputs\n",
    "        \n",
    "def _load_pyfunc(path):\n",
    "    import os\n",
    "    return TransformerONET(os.path.abspath(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2200eaa8",
   "metadata": {},
   "source": [
    "## 5.2 Declaring Model Signatures\n",
    "\n",
    "In the previous Scikit-learn based example notebooks we used the `infer_signature` method to obtain our model signature, referring to the structure & data types of the input data and predicition outputs. Let's therefore explore the manual alternative for creating our model's signature through using MLflow's `Schema` objects.\n",
    "\n",
    "It's important to carefully think through how to best structure our input schema, since loading in a model from MLflow with a set model signature will require any passed data for future predictions to have exactly the same input format. Our model loader is structured to tokenized passed data by referencing the `data['task']` column. Since this model is only being used in a development setting where we have associated class labels, our passed data includes both the task itself and the 37 GWA binary codes. In a production setting with unseen data, the schema would likely be better set as just one text column. \n",
    "\n",
    "The following `Schema` objects for the input and output data use `ColSpec` to specify the column values, their accepted data type, and their column label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "928901f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schema = Schema([\n",
    "  ColSpec(DataType.string, \"Task\"),\n",
    "  ColSpec(DataType.integer, \"4A1a1\"),\n",
    "  ColSpec(DataType.integer, \"4A1a2\"),\n",
    "  ColSpec(DataType.integer, \"4A1b1\"),  \n",
    "  ColSpec(DataType.integer, \"4A1b2\"),  \n",
    "  ColSpec(DataType.integer, \"4A1b3\"),\n",
    "  ColSpec(DataType.integer, \"4A2a1\"),\n",
    "  ColSpec(DataType.integer, \"4A2a2\"),\n",
    "  ColSpec(DataType.integer, \"4A2a3\"),\n",
    "  ColSpec(DataType.integer, \"4A2a4\"),  \n",
    "  ColSpec(DataType.integer, \"4A2b1\"),  \n",
    "  ColSpec(DataType.integer, \"4A2b2\"),\n",
    "  ColSpec(DataType.integer, \"4A1b2\"),\n",
    "  ColSpec(DataType.integer, \"4A2b3\"),\n",
    "  ColSpec(DataType.integer, \"4A2b4\"),\n",
    "  ColSpec(DataType.integer, \"4A2b5\"),  \n",
    "  ColSpec(DataType.integer, \"4A2b6\"),  \n",
    "  ColSpec(DataType.integer, \"4A3a1\"),\n",
    "  ColSpec(DataType.integer, \"4A3a2\"),\n",
    "  ColSpec(DataType.integer, \"4A3a3\"),\n",
    "  ColSpec(DataType.integer, \"4A3a4\"),\n",
    "  ColSpec(DataType.integer, \"4A3b1\"),  \n",
    "  ColSpec(DataType.integer, \"4A3b4\"),  \n",
    "  ColSpec(DataType.integer, \"4A3b6\"),\n",
    "  ColSpec(DataType.integer, \"4A4a1\"),\n",
    "  ColSpec(DataType.integer, \"4A4a2\"),\n",
    "  ColSpec(DataType.integer, \"4A4a3\"),\n",
    "  ColSpec(DataType.integer, \"4A4a4\"),\n",
    "  ColSpec(DataType.integer, \"4A4a5\"),  \n",
    "  ColSpec(DataType.integer, \"4A4a6\"),  \n",
    "  ColSpec(DataType.integer, \"4A4a7\"),\n",
    "  ColSpec(DataType.integer, \"4A4a8\"),\n",
    "  ColSpec(DataType.integer, \"4A4b3\"),\n",
    "  ColSpec(DataType.integer, \"4A4b4\"),\n",
    "  ColSpec(DataType.integer, \"4A4b5\"),  \n",
    "  ColSpec(DataType.integer, \"4A4a6\"),  \n",
    "  ColSpec(DataType.integer, \"4A4c1\"),\n",
    "  ColSpec(DataType.integer, \"4A4c2\"),\n",
    "  ColSpec(DataType.integer, \"4A4c3\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0cc765",
   "metadata": {},
   "source": [
    "Our model output has almost the same schema as the model input, but without the 'Task' text as the original input feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc17499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_schema = Schema([ColSpec(DataType.integer, \"4A1a1\"),\n",
    "  ColSpec(DataType.integer, \"4A1a2\"),\n",
    "  ColSpec(DataType.integer, \"4A1b1\"),  \n",
    "  ColSpec(DataType.integer, \"4A1b2\"),  \n",
    "  ColSpec(DataType.integer, \"4A1b3\"),\n",
    "  ColSpec(DataType.integer, \"4A2a1\"),\n",
    "  ColSpec(DataType.integer, \"4A2a2\"),\n",
    "  ColSpec(DataType.integer, \"4A2a3\"),\n",
    "  ColSpec(DataType.integer, \"4A2a4\"),  \n",
    "  ColSpec(DataType.integer, \"4A2b1\"),  \n",
    "  ColSpec(DataType.integer, \"4A2b2\"),\n",
    "  ColSpec(DataType.integer, \"4A1b2\"),\n",
    "  ColSpec(DataType.integer, \"4A2b3\"),\n",
    "  ColSpec(DataType.integer, \"4A2b4\"),\n",
    "  ColSpec(DataType.integer, \"4A2b5\"),  \n",
    "  ColSpec(DataType.integer, \"4A2b6\"),  \n",
    "  ColSpec(DataType.integer, \"4A3a1\"),\n",
    "  ColSpec(DataType.integer, \"4A3a2\"),\n",
    "  ColSpec(DataType.integer, \"4A3a3\"),\n",
    "  ColSpec(DataType.integer, \"4A3a4\"),\n",
    "  ColSpec(DataType.integer, \"4A3b1\"),  \n",
    "  ColSpec(DataType.integer, \"4A3b4\"),  \n",
    "  ColSpec(DataType.integer, \"4A3b6\"),\n",
    "  ColSpec(DataType.integer, \"4A4a1\"),\n",
    "  ColSpec(DataType.integer, \"4A4a2\"),\n",
    "  ColSpec(DataType.integer, \"4A4a3\"),\n",
    "  ColSpec(DataType.integer, \"4A4a4\"),\n",
    "  ColSpec(DataType.integer, \"4A4a5\"),  \n",
    "  ColSpec(DataType.integer, \"4A4a6\"),  \n",
    "  ColSpec(DataType.integer, \"4A4a7\"),\n",
    "  ColSpec(DataType.integer, \"4A4a8\"),\n",
    "  ColSpec(DataType.integer, \"4A4b3\"),\n",
    "  ColSpec(DataType.integer, \"4A4b4\"),\n",
    "  ColSpec(DataType.integer, \"4A4b5\"),  \n",
    "  ColSpec(DataType.integer, \"4A4a6\"),  \n",
    "  ColSpec(DataType.integer, \"4A4c1\"),\n",
    "  ColSpec(DataType.integer, \"4A4c2\"),\n",
    "  ColSpec(DataType.integer, \"4A4c3\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6882e7",
   "metadata": {},
   "source": [
    "We can then pass both objects directly into MLflow's `ModelSignature` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1061aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature = ModelSignature(inputs = input_schema, outputs = output_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516d0c8c",
   "metadata": {},
   "source": [
    "While `infer_signature` is a simpler approach compared to manually setting Schemas for establishing our model's signature, this alternative strategy may be preferred for ML use cases when the data expected during later stages of a model's lifecycle will be different than what the model was originally trained on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f29d368",
   "metadata": {},
   "source": [
    "## 5.3 Logging Through `mlflow.pyfunc`\n",
    "\n",
    "We have almost everything configured to load our custom `TransformersONET` model into MLflow. We'll just need to add the fine-tuned model and its tokenizer into a temporary directory through transformer's `save_pretrained` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "917a3652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /tmp/tmprspc12q7/config.json\n",
      "Model weights saved in /tmp/tmprspc12q7/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/tmprspc12q7/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/tmprspc12q7/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/tmp/tmprspc12q7/tokenizer_config.json',\n",
       " '/tmp/tmprspc12q7/special_tokens_map.json',\n",
       " '/tmp/tmprspc12q7/vocab.json',\n",
       " '/tmp/tmprspc12q7/merges.txt',\n",
       " '/tmp/tmprspc12q7/added_tokens.json',\n",
       " '/tmp/tmprspc12q7/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempdir = tempfile.mkdtemp()\n",
    "model.save_pretrained(tempdir)\n",
    "tokenizer.save_pretrained(tempdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69b78d4",
   "metadata": {},
   "source": [
    "Let's now break down our specified parameters in the following call to `mlflow.pyfunc.log_model`.\n",
    "\n",
    "`best_model` will be the name of the directory within this run's artifact storage in MLflow that the model, tokenizer, and configuration file is stored into. `data_path` points to the previous created temporary directory where we saved these files. `code_path` links `mlflow.pyfunc.log_model` to our customized model script, while `loader_module` directly points to the code that includes the required `_load_pyfunc` method. `conda_env` points to our directory's conda.yaml file to log for reproducing the model's training environment. `registered_model_name` and `signature` set the title of our model in the Model Registry and pass the signature we just manually instantiated.\n",
    "\n",
    "We'll additionally log this notebook and its helper function file as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb13fdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'hf_onet'.\n",
      "2022/07/13 10:42:03 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: hf_onet, version 1\n",
      "Created version '1' of model 'hf_onet'.\n"
     ]
    }
   ],
   "source": [
    "mlflow.pyfunc.log_model(\"best_model\", \n",
    "                            data_path=tempdir, \n",
    "                            code_path=[\"./pyfiles/model_loader_hf.py\"], \n",
    "                            loader_module=\"model_loader_hf\",\n",
    "                            conda_env=\"../conda.yaml\",\n",
    "                            signature=signature,\n",
    "                            registered_model_name=\"hf_onet\")\n",
    "\n",
    "mlflow.log_artifact(\"hf_transformers_example_4.ipynb\")\n",
    "mlflow.log_artifact(\"./pyfiles/helpers.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c7a328",
   "metadata": {},
   "source": [
    "The above output signifies that our model was successfully logged into MLflow. We didn't have to start the model run we've been tracking throughout this script since transformers does it automatically for us, but we do need to directly end the run ourselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4023268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e663c36",
   "metadata": {},
   "source": [
    "# 6.0 MLflow Tracking UI & Model Registry \n",
    "Let's now refer to the MLflow UI page by switching to `http://<Remote IP>:<Port>/` within our local browser and head to our completed run underneath `hf-onet-experiments`. When we reference our run directly within the MLflow UI, we see that transformers has automatically logged for us 145 parameters for the wide range of customizable training arguments for our model. It's captured performance metrics we originally established such as the F1 score, ROC AUC, and accuracy along with some additional metrics such as the training and evaluation running times in seconds, the number of model optimization steps taken per second, and the cross-entropy loss score. \n",
    "\n",
    "Our model has been stored as a MLflow `MLModel` object which signifies that it'll now be successfully processed by both MLflow itself as well as across diverse deployment settings. Additional artifacts have also been logged such as this Jupyter Notebook, the helper function file, and our model's logged checkpoints during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9f7874",
   "metadata": {},
   "source": [
    "We can also switch to the Models tab in the top navigation bar and verify that our model was successfully registered by our customized model loader method.  \n",
    "\n",
    "![hf_reg.png](../imgs/hf_reg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db145f8",
   "metadata": {},
   "source": [
    "## 6.1 Comparing Models \n",
    "\n",
    "An additional feature to highlight within MLflow is the Compare page, which you can access within individual Experiment logs after selecting the check boxes of at least two model runs. I've separately logged four runs of our TransformersONET model trained for three epochs each, in which the only difference between the runs is their learning rates (2e-5 up to 5e-5). \n",
    "\n",
    "We can visually contrast these runs through multiple plots such as the parallel coordinate plot below: \n",
    "![pcplot.png](../imgs/pcplot.png)\n",
    "The first coordinate establishes which line is associated with each tested learning rate, with the coordinates to follow delineates these model's differences in performance on four evaluation metrics. \n",
    "\n",
    "We can scroll below the Visualization section of the compare page to investigate these metric differences across the four models as well:\n",
    "![num_diffs.png](../imgs/num_diffs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ebb871",
   "metadata": {},
   "source": [
    "# 7.0 Model Loading & Generating Predictions \n",
    "\n",
    "Let's now test whether our custom TransformersONET model loader will correctly instantiate our saved model by using `mlflow.pyfunc.load_model` to retrieve it from the Model Registry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31940e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /tmp/tmp75qfyaqg/data/tmprspc12q7/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"distilroberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"4A1a1\",\n",
      "    \"1\": \"4A1a2\",\n",
      "    \"2\": \"4A1b1\",\n",
      "    \"3\": \"4A1b2\",\n",
      "    \"4\": \"4A1b3\",\n",
      "    \"5\": \"4A2a1\",\n",
      "    \"6\": \"4A2a2\",\n",
      "    \"7\": \"4A2a3\",\n",
      "    \"8\": \"4A2a4\",\n",
      "    \"9\": \"4A2b1\",\n",
      "    \"10\": \"4A2b2\",\n",
      "    \"11\": \"4A2b3\",\n",
      "    \"12\": \"4A2b4\",\n",
      "    \"13\": \"4A2b5\",\n",
      "    \"14\": \"4A2b6\",\n",
      "    \"15\": \"4A3a1\",\n",
      "    \"16\": \"4A3a2\",\n",
      "    \"17\": \"4A3a3\",\n",
      "    \"18\": \"4A3a4\",\n",
      "    \"19\": \"4A3b1\",\n",
      "    \"20\": \"4A3b4\",\n",
      "    \"21\": \"4A3b6\",\n",
      "    \"22\": \"4A4a1\",\n",
      "    \"23\": \"4A4a2\",\n",
      "    \"24\": \"4A4a3\",\n",
      "    \"25\": \"4A4a4\",\n",
      "    \"26\": \"4A4a5\",\n",
      "    \"27\": \"4A4a6\",\n",
      "    \"28\": \"4A4a7\",\n",
      "    \"29\": \"4A4a8\",\n",
      "    \"30\": \"4A4b3\",\n",
      "    \"31\": \"4A4b4\",\n",
      "    \"32\": \"4A4b5\",\n",
      "    \"33\": \"4A4b6\",\n",
      "    \"34\": \"4A4c1\",\n",
      "    \"35\": \"4A4c2\",\n",
      "    \"36\": \"4A4c3\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"4A1a1\": 0,\n",
      "    \"4A1a2\": 1,\n",
      "    \"4A1b1\": 2,\n",
      "    \"4A1b2\": 3,\n",
      "    \"4A1b3\": 4,\n",
      "    \"4A2a1\": 5,\n",
      "    \"4A2a2\": 6,\n",
      "    \"4A2a3\": 7,\n",
      "    \"4A2a4\": 8,\n",
      "    \"4A2b1\": 9,\n",
      "    \"4A2b2\": 10,\n",
      "    \"4A2b3\": 11,\n",
      "    \"4A2b4\": 12,\n",
      "    \"4A2b5\": 13,\n",
      "    \"4A2b6\": 14,\n",
      "    \"4A3a1\": 15,\n",
      "    \"4A3a2\": 16,\n",
      "    \"4A3a3\": 17,\n",
      "    \"4A3a4\": 18,\n",
      "    \"4A3b1\": 19,\n",
      "    \"4A3b4\": 20,\n",
      "    \"4A3b6\": 21,\n",
      "    \"4A4a1\": 22,\n",
      "    \"4A4a2\": 23,\n",
      "    \"4A4a3\": 24,\n",
      "    \"4A4a4\": 25,\n",
      "    \"4A4a5\": 26,\n",
      "    \"4A4a6\": 27,\n",
      "    \"4A4a7\": 28,\n",
      "    \"4A4a8\": 29,\n",
      "    \"4A4b3\": 30,\n",
      "    \"4A4b4\": 31,\n",
      "    \"4A4b5\": 32,\n",
      "    \"4A4b6\": 33,\n",
      "    \"4A4c1\": 34,\n",
      "    \"4A4c2\": 35,\n",
      "    \"4A4c3\": 36\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Didn't find file /tmp/tmp75qfyaqg/data/tmprspc12q7/added_tokens.json. We won't load it.\n",
      "loading file /tmp/tmp75qfyaqg/data/tmprspc12q7/vocab.json\n",
      "loading file /tmp/tmp75qfyaqg/data/tmprspc12q7/merges.txt\n",
      "loading file /tmp/tmp75qfyaqg/data/tmprspc12q7/tokenizer.json\n",
      "loading file None\n",
      "loading file /tmp/tmp75qfyaqg/data/tmprspc12q7/special_tokens_map.json\n",
      "loading file /tmp/tmp75qfyaqg/data/tmprspc12q7/tokenizer_config.json\n",
      "loading weights file /tmp/tmp75qfyaqg/data/tmprspc12q7/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at /tmp/tmp75qfyaqg/data/tmprspc12q7.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "registered_model = mlflow.pyfunc.load_model(\"models:/hf_onet/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9551639",
   "metadata": {},
   "source": [
    "The tokenizer is loaded automatically within our TransformerONET class, so we can move forward with generating predictions following loading in our transformers model. We'll use the 2% of our original task text sample saved as the `predictions` data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01a35f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4A1a1</th>\n",
       "      <th>4A1a2</th>\n",
       "      <th>4A1b1</th>\n",
       "      <th>4A1b2</th>\n",
       "      <th>4A1b3</th>\n",
       "      <th>4A2a1</th>\n",
       "      <th>4A2a2</th>\n",
       "      <th>4A2a3</th>\n",
       "      <th>4A2a4</th>\n",
       "      <th>4A2b1</th>\n",
       "      <th>...</th>\n",
       "      <th>4A4a6</th>\n",
       "      <th>4A4a7</th>\n",
       "      <th>4A4a8</th>\n",
       "      <th>4A4b3</th>\n",
       "      <th>4A4b4</th>\n",
       "      <th>4A4b5</th>\n",
       "      <th>4A4b6</th>\n",
       "      <th>4A4c1</th>\n",
       "      <th>4A4c2</th>\n",
       "      <th>4A4c3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     4A1a1  4A1a2  4A1b1  4A1b2  4A1b3  4A2a1  4A2a2  4A2a3  4A2a4  4A2b1  \\\n",
       "0      1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1      0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "2      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "338    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "339    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "340    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "341    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "342    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "     ...  4A4a6  4A4a7  4A4a8  4A4b3  4A4b4  4A4b5  4A4b6  4A4c1  4A4c2  4A4c3  \n",
       "0    ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "338  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "339  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "340  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "341  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "342  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[343 rows x 37 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registered_model.predict(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4a6f1c",
   "metadata": {},
   "source": [
    "This dataframe of predicted GWA membership confirms that we've successfully fine-tuned our DistilRoBERTa model, logged it into the MLflow Model Registry, and can generate predictions on unseen data with our custom model loader configuration. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b62fa7a496eaa7d4003b27f2d5f7695055336a82372c34d6dbb2c6e9c845aba2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
